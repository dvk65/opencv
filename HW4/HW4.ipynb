{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import torch#use: pip install torch, then restart the kernel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms#pip install torchvision\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boats(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None, gt_json_path=''):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.gt_json_path = gt_json_path\n",
    "        self.labels = json.load(open(gt_json_path, 'r'))\n",
    "        self.image_list = sorted(os.listdir(root_dir))\n",
    "        self.image_ids = dict(enumerate(self.image_list, start=0))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.load_image(idx)\n",
    "        img_name = self.image_ids[idx]\n",
    "        label = self.labels[img_name]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        sample = (img, label)\n",
    "        return sample\n",
    "\n",
    "    def load_image(self, image_index):\n",
    "        image_name = self.image_ids[image_index]\n",
    "        path = os.path.join(self.root_dir, image_name)\n",
    "        img = imread(path)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Net(nn.Module):#TODO 9) #creat your own NN architecture\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(3 * 192 * 108, 1)#TODO Question 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)#TODO Question 2) \n",
    "        x = self.fc1(x)#TODO Question 3) \n",
    "        output = torch.sigmoid(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, criterion, epoch,dry_run):\n",
    "    \"\"\"\n",
    "    Train a network\n",
    "    You can find example code here: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device).float()\n",
    "        optimizer.zero_grad()#TODO Question 4)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, torch.unsqueeze(target, 1))#TODO Question 5)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device).float()\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, torch.unsqueeze(target, 1)).item()  # sum up batch loss\n",
    "            pred = torch.round(output)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/3765 (0%)]\tLoss: 0.191432\n",
      "Train Epoch: 1 [640/3765 (17%)]\tLoss: 0.777203\n",
      "Train Epoch: 1 [1280/3765 (34%)]\tLoss: 0.343819\n",
      "Train Epoch: 1 [1920/3765 (51%)]\tLoss: 0.693856\n",
      "Train Epoch: 1 [2560/3765 (68%)]\tLoss: 0.078079\n",
      "Train Epoch: 1 [3200/3765 (85%)]\tLoss: 0.100373\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 973/1506 (65%)\n",
      "\n",
      "Best accuracy (val): 64.6082337317397\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Training settings #you can mess around with change these values!\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 1\n",
    "    learning_rate = 0.001\n",
    "    no_cuda = False #If you using course cpu leave False, if you are using GPU set true\n",
    "    dry_run = False\n",
    "    seed = random.randint(1,1000)#random seed. Set to constant if you want to train on the same data\n",
    "    log_interval = 10#how many batches to wait before logging training status\n",
    "    save_model = False \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #This is used if you want to run it as a script file.\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Ship Detection')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                        help='learning rate (default: 0.1)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "    args = parser.parse_args()\n",
    "    \"\"\"\n",
    "    #torch.manual_seed(args.seed)\n",
    "    torch.manual_seed(seed)\n",
    "    #use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    use_cuda = no_cuda\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    #train_kwargs = {'batch_size': args.batch_size}\n",
    "    #val_kwargs = {'batch_size': args.test_batch_size}\n",
    "    train_kwargs = {'batch_size': batch_size}\n",
    "    val_kwargs = {'batch_size': test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        val_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    # Create transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # This normalization is used on the test server\n",
    "        transforms.Normalize([0.2404, 0.2967, 0.3563], [0.0547, 0.0527, 0.0477])\n",
    "        ])\n",
    "\n",
    "    # Create train and test set\n",
    "    path_to_dataset = \"Boat-MNIST\"#gobal path to the data on Discovery \n",
    "    train_set = Boats(root_dir=path_to_dataset + \"/train\", transform=transform,\n",
    "                      gt_json_path=path_to_dataset + \"/boat_mnist_labels_trainval.json\")\n",
    "    val_set = Boats(root_dir=path_to_dataset + \"/val\", transform=transform,\n",
    "                    gt_json_path=path_to_dataset +\"/boat_mnist_labels_trainval.json\")\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(val_set, **val_kwargs)\n",
    "\n",
    "    # Create network, optimizer and loss\n",
    "    model = Net().to(device)#TODO Question 6)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)#TODO Question 7)\n",
    "    criterion = nn.MSELoss()#TODO Question 8)\n",
    "\n",
    "    # Train and validate\n",
    "    best_acc = 0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(log_interval, model, device, train_loader, optimizer, criterion, epoch, dry_run)\n",
    "        acc = test(model, device, test_loader, criterion)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"Best accuracy (val): {best_acc}\")\n",
    "\n",
    "    #if args.save_model:\n",
    "    #    torch.save(model.state_dict(), \"model.pth\")\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "    \n",
    "    # --- Do not touch -----\n",
    "    # Save model as onnx file\n",
    "    dummy_input = torch.randn(1, 3, 108, 192, device=device)\n",
    "    input_names = [\"img_1\"]\n",
    "    output_names = [\"output1\"]\n",
    "    torch.onnx.export(model, dummy_input, \"ship_example.onnx\", input_names=input_names, output_names=output_names)\n",
    "    # ----------------------\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
